{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251565c8-29cd-4315-bafb-630fe4cbbe51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import tempfile\n",
    "import IPython\n",
    "import enum\n",
    "import jonlog\n",
    "import json\n",
    "from gtts import gTTS\n",
    "import uuid\n",
    "import datetime as dt\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import base64\n",
    "from github import Github\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import io\n",
    "import retrying\n",
    "import pydub\n",
    "from xml.dom import minidom\n",
    "from xml.etree import ElementTree as ET\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import vertexai\n",
    "import vertexai.preview.generative_models\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage as MistralChatMessage\n",
    "logger = jonlog.getLogger()\n",
    "openai.api_key = os.environ.get(\"OPENAI_KEY\", None) or open('/Users/jong/.openai_key').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526459ff-9ad2-4e56-b11d-dc522fe319b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateLimited:\n",
    "    def __init__(self, max_per_minute):\n",
    "        self.max_per_minute = max_per_minute\n",
    "        self.current_minute = time.strftime('%M')\n",
    "        self.lock = threading.Lock()\n",
    "        self.calls = 0\n",
    "\n",
    "    def __call__(self, fn):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            run = False\n",
    "            with self.lock:\n",
    "                current_minute = time.strftime('%M')\n",
    "                if current_minute != self.current_minute:\n",
    "                    self.current_minute = current_minute\n",
    "                    self.calls = 0\n",
    "                if self.calls < self.max_per_minute:\n",
    "                    self.calls += 1\n",
    "                    run = True\n",
    "            if run:\n",
    "                return fn(*args, **kwargs)\n",
    "            else:\n",
    "                time.sleep(15)\n",
    "                return wrapper(*args, **kwargs)\n",
    "                    \n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e5b9a9-23d5-429c-8e86-32b3d012b9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ElevenLabsTTS:\n",
    "    WOMAN = 'EXAVITQu4vr4xnSDxMaL'\n",
    "    MAN = 'VR6AewLTigWG4xSOukaG'\n",
    "    BRIT_WOMAN = 'jnBYJClnH7m3ddnEXkeh'\n",
    "    def __init__(self, voice_id=None):\n",
    "        api_key_fpath='/Users/jong/.elevenlabs_apikey'\n",
    "        with open(api_key_fpath) as f:\n",
    "            self.api_key = f.read().strip()\n",
    "        self._voice_id = voice_id or self.WOMAN\n",
    "        self.uri = \"https://api.elevenlabs.io/v1/text-to-speech/\" + self._voice_id\n",
    "        \n",
    "    @retrying.retry(stop_max_attempt_number=5, wait_fixed=2000)\n",
    "    def tts(self, text):\n",
    "        headers = {\n",
    "            \"accept\": \"audio/mpeg\",\n",
    "            \"xi-api-key\": self.api_key,\n",
    "        }\n",
    "        payload = {\n",
    "            \"text\": text,\n",
    "        }\n",
    "        return requests.post(self.uri, headers=headers, json=payload).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507cf5f9-cc95-44be-afb2-8c09b2a060d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GttsTTS:\n",
    "    WOMAN = 'us'\n",
    "    MAN   = 'co.in'\n",
    "    def __init__(self, voice_id=None):\n",
    "        self.tld = voice_id\n",
    "\n",
    "    @retrying.retry(stop_max_attempt_number=5, wait_fixed=2000)\n",
    "    def tts(self, text):\n",
    "        speech = gTTS(text=text, lang='en', tld=self.tld, slow=False)\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            temp_filename = f'{tmpdir}/audio'\n",
    "            speech.save(temp_filename)\n",
    "            with open(temp_filename, 'rb') as f:\n",
    "                return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7accf3-a13d-448e-927d-d47d7a3961e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAITTS:\n",
    "    \"\"\"https://platform.openai.com/docs/guides/text-to-speech\"\"\"\n",
    "    WOMAN = 'nova'\n",
    "    MAN = 'echo'\n",
    "    def __init__(self, voice_id=None, model='tts-1'):\n",
    "        \"\"\"Voices:\n",
    "        alloy, echo, fable, onyx, nova, and shimmer\n",
    "        Models:\n",
    "        tts-1, tts-1-hd\n",
    "        \"\"\"\n",
    "        self.voice = voice_id\n",
    "        self.model = model\n",
    "\n",
    "    @RateLimited(95)\n",
    "    @jonlog.retry_with_logging()\n",
    "    def tts(self, text):\n",
    "        response = openai.OpenAI(api_key=openai.api_key).audio.speech.create(\n",
    "          model=self.model,\n",
    "          voice=self.voice,\n",
    "          input=text\n",
    "        )\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e805e7-4928-45dd-9860-4c7f33697d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWSPollyTTS:\n",
    "    WOMAN = 'Kimberly'\n",
    "    MAN = 'Matthew'\n",
    "    BRIT_WOMAN = 'Amy'\n",
    "\n",
    "    def __init__(self, voice_id=None):\n",
    "        self.client = boto3.client('polly', region_name=\"us-east-1\")\n",
    "        self._voice_id = voice_id or self.WOMAN\n",
    "\n",
    "    @RateLimited(95)\n",
    "    @jonlog.retry_with_logging()\n",
    "    def tts(self, text):\n",
    "        response = self.client.synthesize_speech(\n",
    "            Text=text,\n",
    "            OutputFormat='mp3',\n",
    "            VoiceId=self._voice_id,\n",
    "            Engine=\"neural\",\n",
    "        )\n",
    "        # The audio stream containing the synthesized speech\n",
    "        audio_stream = response.get('AudioStream')\n",
    "        return audio_stream.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "765f4de8-d197-434d-9364-e0044ffdf7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_voices(n=2):\n",
    "    return random.sample([\n",
    "        OpenAITTS(voice_id=vid) for vid in ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']\n",
    "    ] + [\n",
    "        AWSPollyTTS(voice_id=vid) for vid in ['Kimberly', 'Matthew', 'Amy']\n",
    "    ], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46f8d0ca-2a36-4b5a-b39c-d19e0f94d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWSChat:\n",
    "    MODELS = {\n",
    "        \"claude-instant\": \"anthropic.claude-instant-v1\",\n",
    "        \"claude-best\": \"anthropic.claude-v2:1\",\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def msg(cls, messages=None, model=\"anthropic.claude-instant-v1\", **kwargs):\n",
    "        client = boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "        try:\n",
    "            # The different model providers have individual request and response formats.\n",
    "            # For the format, ranges, and default values for Anthropic Claude, refer to:\n",
    "            # https://docs.anthropic.com/claude/reference/complete_post\n",
    "\n",
    "            # Claude requires you to enclose the prompt as follows:\n",
    "            # enclosed_prompt = \"Human: \" + prompt + \"\\n\\nAssistant:\"\n",
    "            prompt = \"\\n\\n\".join(\n",
    "                [f'{\"\" if (msg[\"role\"] == \"system\" and model == cls.MODELS[\"claude-best\"]) else (\"Human\" if msg[\"role\"] != \"assistant\" else \"Assistant\")}: {msg[\"content\"]}' for msg in messages] +\n",
    "                [\"Assistant:\"]\n",
    "            )\n",
    "\n",
    "            if 'temperature' not in kwargs:\n",
    "                kwargs['temperature'] = 1\n",
    "            body = {\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens_to_sample\": 2048,\n",
    "                **kwargs\n",
    "            }\n",
    "            response = client.invoke_model(\n",
    "                modelId=model, body=json.dumps(body)\n",
    "            )\n",
    "            response_body = json.loads(response[\"body\"].read())\n",
    "            completion = response_body[\"completion\"]\n",
    "            return completion\n",
    "        except ClientError as e:\n",
    "            logger.exception(f\"Couldn't invoke {model}\", e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aaeccd5-5c89-44ec-9d65-4afe4b95b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleChat:\n",
    "    MODELS = {\n",
    "        \"gemini-pro\": \"gemini-pro\",\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def consolidate_messages(cls, message_list):\n",
    "        if not message_list:\n",
    "            return []\n",
    "        consolidated = []\n",
    "        current_role = None\n",
    "        current_content = \"\"\n",
    "\n",
    "        for message in message_list:\n",
    "            role = message.get(\"role\")\n",
    "            content = message.get(\"content\", \"\")\n",
    "    \n",
    "            if role == \"system\":\n",
    "                role = \"user\"\n",
    "            if role == current_role:\n",
    "                current_content += \"\\n\" + content\n",
    "            else:\n",
    "                if current_role is not None:\n",
    "                    consolidated.append({\"role\": current_role, \"content\": current_content})\n",
    "                current_content = content\n",
    "                current_role = role\n",
    "    \n",
    "        if current_role is not None:\n",
    "            consolidated.append({\"role\": current_role, \"content\": current_content})\n",
    "    \n",
    "        return consolidated\n",
    "\n",
    "    @classmethod\n",
    "    def msg(cls, messages=None, model=\"gemini-pro\", **kwargs):\n",
    "        vertexai.init(project='summer2023-392312', location='us-central1')\n",
    "        model = vertexai.preview.generative_models.GenerativeModel(model)\n",
    "        contents = [vertexai.generative_models._generative_models.Content(\n",
    "            role=\"user\" if msg[\"role\"] != \"assistant\" else \"model\",\n",
    "            parts=[vertexai.generative_models._generative_models.Part.from_text(msg[\"content\"])]\n",
    "        ) for msg in cls.consolidate_messages(messages)]\n",
    "        response = model.generate_content(contents=contents)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1682e3e-2215-49aa-9160-7d5809e423e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MistralChat:\n",
    "    MODELS = {\n",
    "        \"mistral-medium\": \"mistral-medium\",\n",
    "        \"mistral-small\": \"mistral-small\",\n",
    "    }\n",
    "    api_key = os.environ.get(\"MISTRAL_API_KEY\") or open('/Users/jong/.mistral_apikey').read().strip()\n",
    "\n",
    "    @classmethod\n",
    "    def consolidate_messages(cls, message_list):\n",
    "        if not message_list:\n",
    "            return []\n",
    "    \n",
    "        consolidated = []\n",
    "        current_role = None\n",
    "        current_content = \"\"\n",
    "    \n",
    "        for message in message_list:\n",
    "            role = message[\"role\"]\n",
    "            content = message[\"content\"]\n",
    "\n",
    "            if role == current_role:\n",
    "                current_content += \"\\n\" + content\n",
    "            else:\n",
    "                if current_role is not None:\n",
    "                    consolidated.append({\"role\": current_role, \"content\": current_content})\n",
    "                current_content = content\n",
    "                current_role = role\n",
    "    \n",
    "        if current_role is not None:\n",
    "            consolidated.append({\"role\": current_role, \"content\": current_content})\n",
    "\n",
    "        return consolidated\n",
    "\n",
    "    @classmethod\n",
    "    def msg(cls, messages=None, model=\"mistral-medium\", **kwargs):\n",
    "        client = MistralClient(api_key=cls.api_key)\n",
    "        if not any(msg['role'] == 'user' for msg in messages):\n",
    "            messages[-1]['role'] = 'user'\n",
    "        chat_response = client.chat(\n",
    "            model=model,\n",
    "            messages=[MistralChatMessage(**msg) for msg in cls.consolidate_messages(messages)],\n",
    "        )\n",
    "        return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2ea46ab-a973-4ad2-852b-2613274dd9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEFAULT_MODEL = 'gpt-4-1106-preview'\n",
    "# DEFAULT_LENGTH  = 80_000\n",
    "DEFAULT_MODEL = 'gpt-3.5-turbo'\n",
    "DEFAULT_LENGTH  = 29_000\n",
    "\n",
    "class Chat:\n",
    "    class Model(enum.Enum):\n",
    "        GPT3_5 = \"gpt-3.5-turbo\"\n",
    "        GPT_4  = \"gpt-4-turbo-preview\"\n",
    "\n",
    "    def __init__(self, system, max_length=DEFAULT_LENGTH):\n",
    "        self._system = system\n",
    "        self._max_length = max_length\n",
    "        self._history = [\n",
    "            {\"role\": \"system\", \"content\": self._system},\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def num_tokens_from_text(cls, text, model=DEFAULT_MODEL):\n",
    "        \"\"\"Returns the number of tokens used by some text.\"\"\"\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(model)\n",
    "        except:\n",
    "            encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')  # Lol openai probably the same\n",
    "        return len(encoding.encode(text))\n",
    "    \n",
    "    @classmethod\n",
    "    def num_tokens_from_messages(cls, messages, model=DEFAULT_MODEL):\n",
    "        \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(model)\n",
    "        except:\n",
    "            encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')  # Lol openai probably the same\n",
    "        num_tokens = 0\n",
    "        for message in messages:\n",
    "            num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "            for key, value in message.items():\n",
    "                num_tokens += len(encoding.encode(value))\n",
    "                if key == \"name\":  # if there's a name, the role is omitted\n",
    "                    num_tokens += -1  # role is always required and always 1 token\n",
    "        num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "        return num_tokens\n",
    "\n",
    "    @retrying.retry(stop_max_attempt_number=5, wait_fixed=2000)\n",
    "    def _msg(self, *args, model=DEFAULT_MODEL, **kwargs):\n",
    "        logger.info(f'requesting chatcompletion {model=}...')\n",
    "        if model.startswith(\"AWS/\"):\n",
    "            model = model[4:]\n",
    "            resp = AWSChat.msg(\n",
    "                messages=self._history,\n",
    "                **kwargs\n",
    "            )\n",
    "        elif model.startswith(\"GOOGLE/\"):\n",
    "            model = model[7:]\n",
    "            resp = GoogleChat.msg(messages=self._history, model=model, **kwargs)\n",
    "        elif model.startswith(\"MISTRAL/\"):\n",
    "            model = model[8:]\n",
    "            resp = MistralChat.msg(messages=self._history, model=model, **kwargs)\n",
    "        else:\n",
    "            resp = openai.OpenAI(api_key=openai.api_key).chat.completions.create(\n",
    "                *args,\n",
    "                model=model,\n",
    "                messages=self._history,\n",
    "                **kwargs\n",
    "            ).choices[0].message.content\n",
    "        logger.info(f'received chatcompletion {model=}...')\n",
    "        return resp\n",
    "    \n",
    "    def message(self, next_msg=None, **kwargs):\n",
    "        # TODO: Optimize this if slow through easy caching\n",
    "        while len(self._history) > 1 and self.num_tokens_from_messages(self._history) > self._max_length:\n",
    "            logger.info(f'Popping message: {self._history.pop(1)}')\n",
    "        if next_msg is not None:\n",
    "            self._history.append({\"role\": \"user\", \"content\": next_msg})\n",
    "        logger.info(f'Currently at {self.num_tokens_from_messages(self._history)=} tokens in conversation')\n",
    "        resp = self._msg(**kwargs)\n",
    "        text = resp\n",
    "        self._history.append({\"role\": \"assistant\", \"content\": text})\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a0eef7-3b50-4ca7-9210-2042d7adbe00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "class PodcastChat(Chat):\n",
    "    def __init__(self, topic, podcast=\"award winning\", max_length=DEFAULT_LENGTH, hosts=['Tom', 'Jen'], host_voices=[AWSPollyTTS(AWSPollyTTS.MAN), OpenAITTS(OpenAITTS.WOMAN)], extra_system=None):\n",
    "        system = f\"\"\"You are an {podcast} podcast with hosts {hosts[0]} and {hosts[1]}.\n",
    "Respond with the hosts names before each line like {hosts[0]}: and {hosts[1]}:\"\"\".replace(\"\\n\", \" \")\n",
    "        if extra_system is not None:\n",
    "            system = '\\n'.join([system, extra_system])\n",
    "        super().__init__(system, max_length=max_length)\n",
    "        self._podcast = podcast\n",
    "        self._topic = topic\n",
    "        self._hosts = hosts\n",
    "        self._history.append({\n",
    "            \"role\": \"user\", \"content\": f\"\"\"Generate an informative, entertaining, and very detailed podcast episode about {topic}.\n",
    "Make sure to teach complex topics in an intuitive way.\"\"\".replace(\"\\n\", \" \")\n",
    "        })\n",
    "        self._tts_h1, self._tts_h2 = host_voices\n",
    "\n",
    "    def text2speech(self, text, spacing_ms=350):\n",
    "        tmpdir = '/tmp'\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as thread_pool:\n",
    "            i = 0\n",
    "            jobs = []\n",
    "            def write_audio(msg, i, voice, **kwargs):\n",
    "                logger.info(f'requesting tts {i=} {voice=}')\n",
    "                s = voice.tts(msg)\n",
    "                logger.info(f'received tts {i=} {voice=}')\n",
    "                return s\n",
    "\n",
    "            text = text.replace('\\n', '!!!LINEBREAK!!!').replace('\\\\', '').replace('\"', '')\n",
    "            # Build text one at a time\n",
    "            currline, currname = \"\", self._hosts[0]\n",
    "            name2tld = {self._hosts[0]: 'co.uk', self._hosts[1]: 'com'}\n",
    "            name2voice = {self._hosts[0]: self._tts_h1, self._hosts[1]: self._tts_h2}\n",
    "            audios = []\n",
    "            for line in text.split(\"!!!LINEBREAK!!!\"):\n",
    "                if not line.strip(): continue\n",
    "                if line.startswith(f\"{self._hosts[0]}: \") or line.startswith(f\"{self._hosts[1]}: \"):\n",
    "                    if currline:\n",
    "                        jobs.append(thread_pool.submit(write_audio, currline, i, name2voice[currname], lang='en', tld=name2tld[currname]))\n",
    "                        i += 1\n",
    "                    currline = line[4:]\n",
    "                    currname = line[:3]\n",
    "                else:\n",
    "                    currline += line\n",
    "            if currline:\n",
    "                jobs.append(thread_pool.submit(write_audio, currline, i, name2voice[currname], lang='en', tld=name2tld[currname]))\n",
    "                i+=1\n",
    "            # Concat files\n",
    "            audios = [job.result() for job in jobs]\n",
    "            logger.info('concatting audio')\n",
    "            audio = merge_mp3s(audios)\n",
    "            logger.info('done with audio!')\n",
    "            IPython.display.display(IPython.display.Audio(audio, autoplay=False))\n",
    "            return audio\n",
    "            \n",
    "    def step(self, msg=None, skip_aud=False, ret_aud=True, min_length=None, **kwargs):\n",
    "        msg = self.message(msg, **kwargs)\n",
    "        if min_length is not None and len(msg) < min_length:\n",
    "            raise ValueError(f\"Message [{msg}] is shorter than {min_length=}\")\n",
    "        if skip_aud: return msg\n",
    "        aud = self.text2speech(msg)\n",
    "        if ret_aud: return msg, aud\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c88be541-f005-412f-abc0-7cfa159e7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodcastXMLHandler:\n",
    "    def __init__(self):\n",
    "        self.root = ET.Element(\"channel\")  # 'channel' is typically used in podcast RSS feeds\n",
    "        self.tree = ET.ElementTree(self.root)\n",
    "\n",
    "    def to_xml(self, filepath):\n",
    "        self.tree.write(filepath, encoding='utf-8', xml_declaration=True, pretty_print=True)\n",
    "\n",
    "    @classmethod\n",
    "    def from_xml(cls, filepath):\n",
    "        self = cls()\n",
    "        self.tree = ET.parse(filepath)\n",
    "        self.root = self.tree.getroot()\n",
    "        return self\n",
    "\n",
    "    def contains_episode(self, episode_name):\n",
    "        for episode in self.root.findall('./channel/item'):\n",
    "            title = episode.find('title').text\n",
    "            if title == episode_name:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def remove_episodes_older_than(self, limit):\n",
    "        now = datetime.datetime.now()\n",
    "        for episode in self.root.findall('./channel/item'):\n",
    "            pub_date = datetime.datetime.strptime(episode.find('pubDate').text, '%a, %d %b %Y %H:%M:%S %Z')  # RSS date format\n",
    "            if now - pub_date > limit:\n",
    "                episode.getparent().remove(episode)\n",
    "\n",
    "    def add_episode(self, episode_details):\n",
    "        episode = ET.SubElement(self.root, './channel/item')\n",
    "        for key, value in episode_details.items():\n",
    "            ET.SubElement(episode, key).text = str(value)\n",
    "\n",
    "\"\"\"\n",
    "pd = PodcastXMLHandler.from_xml('/Users/jong/Downloads/podcast.xml')\n",
    "pd.contains_episode('cs.IR: Recent Research Papers on Data Science and Cybersecurity.')\n",
    "pd.remove_episodes_older_than(datetime.timedelta(days=30))\n",
    "pd.to_xml('/Users/jong/Downloads/podcast2.xml')\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cb12748-5a8a-4b27-b688-2e7bc583be17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PodcastRSSFeed:\n",
    "    \"\"\"Class to handle rss feed operations using github pages.\"\"\"\n",
    "\n",
    "    def __init__(self, org, repo, xml_path, clean_timedelta=None):\n",
    "        self.org = org\n",
    "        self.repo = repo\n",
    "        self.xml_path = xml_path\n",
    "        self.local_xml_path = self.download_podcast_xml()\n",
    "        self.clean_timedelta = clean_timedelta\n",
    "\n",
    "    def get_file_base64(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            return base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "    def download_podcast_xml(self):\n",
    "        outfile = tempfile.NamedTemporaryFile().name + '.xml'\n",
    "        raw_url = f'https://raw.githubusercontent.com/{self.org}/{self.repo}/main/{self.xml_path}'\n",
    "        response = requests.get(raw_url)\n",
    "        print(raw_url)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(response.text)\n",
    "        with open(outfile, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return outfile\n",
    "\n",
    "    def update_podcast_xml(self, xml_data, file_name, episode_title, episode_description, file_length):\n",
    "        # Parse XML\n",
    "        root = ET.fromstring(xml_data)\n",
    "        channel = root.find('channel')\n",
    "\n",
    "        file_extension = os.path.splitext(file_name)[-1].lower()[1:]\n",
    "        content_type = 'audio/' + file_extension\n",
    "        \n",
    "        # Add new episode\n",
    "        item = ET.SubElement(channel, 'item')\n",
    "        ET.SubElement(item, 'title').text = episode_title\n",
    "        ET.SubElement(item, 'description').text = episode_description\n",
    "        ET.SubElement(item, 'pubDate').text = dt.datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')\n",
    "        ET.SubElement(item, 'enclosure', {\n",
    "            'url': f'https://{self.org}.github.io/{file_name}',\n",
    "            'type': content_type,\n",
    "            'length': str(file_length),\n",
    "        })\n",
    "        ET.SubElement(item, 'guid').text = str(uuid.uuid4())\n",
    "\n",
    "        # Convert back to string and pretty-format\n",
    "        pretty_xml = minidom.parseString(ET.tostring(root)).toprettyxml(indent='  ')\n",
    "        # Remove extra newlines\n",
    "        pretty_xml = os.linesep.join([s for s in pretty_xml.splitlines() if s.strip()])\n",
    "\n",
    "        return pretty_xml\n",
    "\n",
    "    def remove_episodes_older_than(self, xml_data, limit):\n",
    "        now = dt.datetime.now()\n",
    "        root = ET.fromstring(xml_data)\n",
    "        for episode in root.findall('./channel/item'):\n",
    "            pub_date = dt.datetime.strptime(episode.find('pubDate').text, '%a, %d %b %Y %H:%M:%S %Z')  # RSS date format\n",
    "            if now - pub_date > limit:\n",
    "                episode_path = episode.find('enclosure').attrib['url'].split('.github.io/', 1)[1]\n",
    "                logger.info(f\"Deleting old episode: {episode_path}\")\n",
    "                episode.getparent().remove(episode)\n",
    "                # Get the repository\n",
    "                try:\n",
    "                    repo = gh.get_user().get_repo(self.repo)\n",
    "                except:\n",
    "                    repo = gh.get_organization(self.org).get_repo(self.repo)\n",
    "                try:\n",
    "                    repo.delete_file(episode_path, \"remove test\", contents.sha, branch=\"test\")\n",
    "                except Exception as e:\n",
    "                    logger.exception(e)\n",
    "        # Convert back to string and pretty-format\n",
    "        pretty_xml = minidom.parseString(ET.tostring(root)).toprettyxml(indent='  ')\n",
    "        # Remove extra newlines\n",
    "        pretty_xml = os.linesep.join([s for s in pretty_xml.splitlines() if s.strip()])\n",
    "        return pretty_xml\n",
    "    \n",
    "    def upload_episode(self, file_path, file_name, episode_title, episode_description):\n",
    "        # Authenticate with GitHub\n",
    "        token = os.environ.get(\"GH_KEY\", None) or open(\"/Users/jong/.gh_token\").read().strip()\n",
    "        gh = Github(token)\n",
    "\n",
    "        # Get the repository\n",
    "        try:\n",
    "            repo = gh.get_user().get_repo(self.repo)\n",
    "        except:\n",
    "            repo = gh.get_organization(self.org).get_repo(self.repo)\n",
    "\n",
    "        # Upload the audio file\n",
    "        podsha = None\n",
    "        try:\n",
    "            podsha = repo.get_contents(file_name).sha\n",
    "        except:\n",
    "            pass\n",
    "        with open(file_path, 'rb') as audio_file:\n",
    "            audio_data = audio_file.read()\n",
    "            self.upload_to_github(file_name, audio_data, f'Upload new episode: {file_name}', podsha)\n",
    "\n",
    "        # Update and upload the podcast.xml file\n",
    "        file_length = os.path.getsize(file_path)\n",
    "        podcast_xml = repo.get_contents(self.xml_path)\n",
    "        xml_data = base64.b64decode(podcast_xml.content).decode('utf-8')\n",
    "        xml_data = self.update_podcast_xml(xml_data, file_name, episode_title, episode_description, file_length)\n",
    "        self.upload_to_github(self.xml_path, xml_data, f'Update podcast.xml with new episode: {file_name}', podcast_xml.sha)\n",
    "\n",
    "    def upload_to_github(self, file_name, file_content, commit_message, sha=None):\n",
    "        # Prepare API request headers\n",
    "        token = os.environ.get(\"GH_KEY\", None) or open(\"/Users/jong/.gh_token\").read().strip()\n",
    "        gh = Github(token)\n",
    "        # Get the repository\n",
    "        try:\n",
    "            repo = gh.get_user().get_repo(self.repo)\n",
    "        except:\n",
    "            repo = gh.get_organization(self.org).get_repo(self.repo)\n",
    "\n",
    "        if sha:\n",
    "            repo.update_file(file_name, commit_message, file_content, sha)\n",
    "        else:\n",
    "            repo.create_file(file_name, commit_message, file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fea16c5-3d56-4277-a6eb-d74667b64435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Episode:\n",
    "    def __init__(self, episode_type='narration', podcast_args=(\"JonathanGrant\", \"jonathangrant.github.io\", \"podcasts/podcast.xml\"), text_model=DEFAULT_MODEL, **chat_kwargs):\n",
    "        \"\"\"\n",
    "        Kinds of episodes:\n",
    "            pure narration - simple TTS\n",
    "            simple podcast - Text to Podcast\n",
    "            complex podcast?\n",
    "        \"\"\"\n",
    "        self.episode_type = episode_type\n",
    "        self.chat = PodcastChat(**chat_kwargs)\n",
    "        self.chat_kwargs = chat_kwargs\n",
    "        self.pod = PodcastRSSFeed(*podcast_args)\n",
    "        self.text_model = text_model\n",
    "        self.sounds = []\n",
    "        self.texts = []\n",
    "\n",
    "    def get_outline(self, n, topic=None):\n",
    "        if topic is None: topic = self.chat._topic\n",
    "        chat = Chat(f\"\"\"Write \n",
    "a concise plaintext outline with exactly {n} parts for a podcast titled {self.chat._podcast}.\n",
    "Only return the parts and nothing else.\n",
    "Do not include a conclusion or intro.\n",
    "Do not write more than {n} parts.\n",
    "Format it like this: 1. insert-title-here, 2. another-title-here, ...\"\"\".replace(\"\\n\", \" \"))\n",
    "        resp = chat.message(model=self.text_model)\n",
    "        chapter_pattern = re.compile(r'\\d+\\.\\s+.*')\n",
    "        chapters = chapter_pattern.findall(resp)\n",
    "        if not chapters:\n",
    "            logger.warning(f'Could not parse message for chapters! Message:\\n{resp}')\n",
    "        return chapters\n",
    "\n",
    "    def step(self, msg=None, nparts=3):\n",
    "        include = f\" Remember to respond with the hosts names like {self.chat._hosts[0]}: and {self.chat._hosts[1]}:\"\n",
    "        msg = msg or self.chat._topic\n",
    "        if self.episode_type == 'narration':\n",
    "            outline = self.get_outline(msg, nparts)\n",
    "            logger.info(f\"Outline: {outline}\")\n",
    "            intro_txt, intro_aud = self.chat.step(f\"Write the intro for a podcast about {msg}. The outline for the podcast is {', '.join(outline)}. Only write the introduction.{include}\", model=self.text_model)\n",
    "            self.sounds.append(intro_aud)\n",
    "            self.texts.append(intro_txt)\n",
    "            # Get parts\n",
    "            for part in outline:\n",
    "                logger.info(f\"Part: {part}\")\n",
    "                part_txt, part_aud = self.chat.step(f\"Write the next part: {part}.{include}\", model=self.text_model)\n",
    "                self.sounds.append(part_aud)\n",
    "                self.texts.append(part_txt)\n",
    "            # Get conclusion\n",
    "            logger.info(\"Conclusion\")\n",
    "            part_txt, part_aud = self.chat.step(f\"Write the conclusion. Remember, the outline was: {', '.join(outline)}.{include}\", model=self.text_model)\n",
    "            self.sounds.append(part_aud)\n",
    "            self.texts.append(part_txt)\n",
    "        elif self.episode_type == 'pure_tts':\n",
    "            outline = None\n",
    "            audio = self.chat.text2speech(\"\\n\".join([self.chat._hosts[i%2]+\": \"+x for i,x in enumerate(msg)]))\n",
    "            self.sounds.append(audio)\n",
    "            self.texts.extend(msg)\n",
    "        return outline, '\\n'.join(self.texts)\n",
    "\n",
    "    def upload(self, title, descr):\n",
    "        title_small = title.lower().replace(\" \", \"_\")[:16] + str(uuid.uuid4())  # I had a filename too long once\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            tmppath = os.path.join(tmpdir, \"audio_file.mp3\")\n",
    "            with open(tmppath, \"wb\") as f:\n",
    "                f.write(merge_mp3s(self.sounds))\n",
    "            self.pod.upload_episode(tmppath, f\"podcasts/audio/{title_small}.mp3\", title, descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75d0a7d1-de77-4129-a15c-537c7919b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_mp3s(mp3_bytes_list):\n",
    "    \"\"\"\n",
    "    Merges multiple MP3 bytestrings into a single MP3 bytestring.\n",
    "    \n",
    "    :param mp3_bytes_list: List of MP3 bytestrings\n",
    "    :return: Merged MP3 as bytestring\n",
    "    \"\"\"\n",
    "    # Convert the first MP3 bytestring to an AudioSegment\n",
    "    combined = pydub.AudioSegment.from_file(io.BytesIO(mp3_bytes_list[0]), format=\"mp3\")\n",
    "\n",
    "    # Loop through the rest of the MP3 bytestrings and append them\n",
    "    for mp3_bytes in mp3_bytes_list[1:]:\n",
    "        next_segment = pydub.AudioSegment.from_file(io.BytesIO(mp3_bytes), format=\"mp3\")\n",
    "        combined += next_segment\n",
    "\n",
    "    # Export the combined audio to a bytestring\n",
    "    combined_buffer = io.BytesIO()\n",
    "    combined.export(combined_buffer, format=\"mp3\")\n",
    "    return combined_buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1132bda8-7767-4f78-9789-046c4af27a72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ep = Episode(\n",
    "#     episode_type='narration',\n",
    "#     topic=\"Hidden History: Unraveling 3 of History's Funniest Mysteries from the 1st Century\",\n",
    "#     max_length=29_000,\n",
    "#     # text_model='gpt-4-1106-preview',\n",
    "#     text_model='GOOGLE/gemini-pro',\n",
    "# )\n",
    "# outline, txt = ep.step(nparts='3')\n",
    "# ep.upload(\"[Google Gemini] Hidden History: Unraveling 3 of History's Funniest Mysteries from the 1st Century\", \"Hidden History: Unraveling 3 of History's Funniest Mysteries from the 1st Century\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10148079-8f23-4b46-8810-98c1d6483680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
