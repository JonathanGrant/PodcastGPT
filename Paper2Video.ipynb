{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987e1c5d-936a-4a35-bde2-cd01028340dd",
   "metadata": {},
   "source": [
    "# Idea is to take a paper / pdf and convert it to a lecture that explains it intuitively.\n",
    "\n",
    "### Steps:\n",
    "1. Download PDF and get text\n",
    "2. Ask ChatGPT what concepts (in order) need to be understood to understand the paper\n",
    "3. Create video Script\n",
    "4. Create video images\n",
    "5. Add audio on top of images\n",
    "6. Join and done\n",
    "\n",
    "### What to display in video?\n",
    "* Ask Chat for slide text (md format or something) given a paragraph\n",
    "\n",
    "### Video Outline:\n",
    "1. Concepts / Building blocks\n",
    "2. Paper summary\n",
    "3. Each part of the paper (ask Chat for parts)\n",
    "4. Conclusion and Implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee88f59f-565b-47d4-9327-2e0b5f14d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "from ChatPodcastGPT import Chat, PodcastChat, OpenAITTS, get_random_voices\n",
    "import collections\n",
    "import concurrent.futures\n",
    "import os\n",
    "import feedparser\n",
    "import structlog\n",
    "import itertools\n",
    "import enum\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import PyPDF2\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import retrying\n",
    "import openai\n",
    "import random\n",
    "import IPython.display\n",
    "import datetime\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "import base64\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "import numpy as np\n",
    "import io\n",
    "import subprocess\n",
    "import os\n",
    "import functools\n",
    "import logging\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import threading\n",
    "import traceback\n",
    "import inspect\n",
    "\n",
    "\n",
    "# MODEL = 'gpt-3.5-turbo-16k'\n",
    "MODEL = 'AWS/claude-3-haiku'\n",
    "MAX_TOKENS = 120_000\n",
    "# MAX_TOKENS = 2_000\n",
    "JOIN_NUM_DEFAULT = 300\n",
    "SPEAKER_NAMES = ['Alfred', 'Alice']\n",
    "SPEAKER_VOICES = get_random_voices(2, openai=False, aws=False)\n",
    "MAX_WORKERS = 4\n",
    "flatten_list = lambda a: list(itertools.chain(*[x for x in a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db918fd1-d558-4fab-83c6-4f1cbd0f5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_thread_id(logger, log_method, event_dict):\n",
    "    \"\"\"\n",
    "    Add the thread ID to the event_dict if the current execution is within a thread.\n",
    "    \"\"\"\n",
    "    if threading.current_thread() != threading.main_thread():\n",
    "        event_dict[\"thread_id\"] = threading.get_ident()\n",
    "        event_dict[\"thread_name\"] = threading.current_thread().name\n",
    "    else:\n",
    "        event_dict[\"thread_id\"] = \"[Main]\"\n",
    "    return event_dict\n",
    "\n",
    "# Configure structlog\n",
    "structlog.configure(\n",
    "    processors=[\n",
    "        structlog.stdlib.add_log_level,\n",
    "        structlog.stdlib.add_logger_name,\n",
    "        add_thread_id,\n",
    "        structlog.stdlib.PositionalArgumentsFormatter(),\n",
    "        structlog.processors.TimeStamper(fmt=\"iso\"),\n",
    "        structlog.dev.ConsoleRenderer()\n",
    "    ],\n",
    "    context_class=dict,\n",
    "    logger_factory=structlog.stdlib.LoggerFactory(),\n",
    "    wrapper_class=structlog.stdlib.BoundLogger,\n",
    "    cache_logger_on_first_use=True,\n",
    ")\n",
    "logging.getLogger('moviepy').setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(stream=sys.stdout, format=\"%(message)s\", level=logging.INFO)\n",
    "logger = structlog.get_logger(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7f8372-dd4c-4c50-8e1d-be8fcb4a620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-15T00:04:48.825335Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mhello                         \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d9ef8a-c9f9-43b0-bbdf-951b8b641d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_exception(exception, func_name):\n",
    "    \"\"\"Log the exception with its stack trace and the function name.\"\"\"\n",
    "    stack_trace = traceback.format_exc()\n",
    "    logger.error(f\"Exception in {func_name}: {exception}\\n{stack_trace}\")\n",
    "    return True\n",
    "\n",
    "def retry_with_logging(stop_max_attempt_number=5, wait_fixed=2000):\n",
    "    def decorator(func):\n",
    "        @retrying.retry(stop_max_attempt_number=stop_max_attempt_number, wait_fixed=wait_fixed,\n",
    "               retry_on_exception=lambda exception: log_exception(exception, func.__name__))\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459e615-25d1-48f5-8e8c-d02b0e527716",
   "metadata": {},
   "source": [
    "## 1. PDF to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f5cfcc-d760-46be-b589-07548d97f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "        text = ''\n",
    "        for page_number in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_number]\n",
    "            text += page.extract_text()\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966042dc-f97a-49a4-9a5e-beff09e3a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_path = '/Users/jong/Downloads/covid_garbage.pdf'\n",
    "# paper_text = extract_text_from_pdf(paper_path)\n",
    "# len(paper_text), paper_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b71680-46d5-4ac6-94c1-61bd12fae9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_into_token_chunks(text, max_tokens=MAX_TOKENS, smoothing=0):\n",
    "    \"\"\"Split the text into parts based on tokens.\"\"\"\n",
    "    sentences = text.replace('\\n', '').split(\".\")\n",
    "    all_parts = []\n",
    "    current_part = []\n",
    "    for sentence in sentences:\n",
    "        current_part.append(sentence + '.')\n",
    "        if Chat.num_tokens_from_text(' '.join(current_part)) > max_tokens:\n",
    "            part_text = ' '.join(current_part[:-1])\n",
    "            all_parts.append(part_text)\n",
    "            current_part = current_part[-(smoothing+1):]\n",
    "\n",
    "    if current_part:\n",
    "        all_parts.append(' '.join(current_part[:-1]))\n",
    "    return all_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8cf0cc9-981e-434a-9b81-4846bbd6748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_sections = text_into_token_chunks(paper_text, smoothing=3)\n",
    "# len(paper_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea69d579-66b1-4fa7-9aaf-803910932cef",
   "metadata": {},
   "source": [
    "# 2. Concepts needed for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a7e891-3362-43dc-9a53-e5c22bb603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def help_load_json(txt):\n",
    "    if txt.startswith(\"```json\\n\"):\n",
    "        return txt.split(\"```json\\n\", maxsplit=1)[1].rsplit(\"```\")[0]\n",
    "    return txt\n",
    "\n",
    "@retry_with_logging()\n",
    "def get_concepts(paper_section):\n",
    "    chat = Chat('''Given some text from a scientific journal, return a JSON formatted list containing a few prerequisite concepts needed for understanding the paper.\n",
    "Respond only a JSON list and nothing else.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    resp = chat.message(paper_section, model=MODEL)\n",
    "    try:\n",
    "        data = json.loads(help_load_json(resp))\n",
    "        assert isinstance(data, list)\n",
    "    except:\n",
    "        logger.critical(f\"get_concepts Cannot parse resp: {resp}\")\n",
    "        raise\n",
    "    return data\n",
    "\n",
    "@retry_with_logging()\n",
    "def merge_concepts(concepts):\n",
    "    if len(concepts) <= 6:\n",
    "        return concepts\n",
    "    chat = Chat('''Given a list of concepts needed to understand a paper, reduce them to just 5 or fewer prerequisite concepts.\n",
    "Only respond as a valid JSON list, and nothing else. Order the list from least to most complex.'''.replace('\\n', ' '))\n",
    "    resp = chat.message(str(concepts), model=MODEL)\n",
    "    try:\n",
    "        data = json.loads(help_load_json(resp))\n",
    "        assert isinstance(data, list)\n",
    "    except:\n",
    "        logger.critical(f\"merge_concepts Cannot parse resp: {resp}\")\n",
    "        raise\n",
    "    assert isinstance(data, list)\n",
    "    return data\n",
    "\n",
    "def get_all_concepts(paper_sections):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max(MAX_WORKERS//4, 1)) as tpe:\n",
    "        concepts = [\n",
    "            concept\n",
    "            for concepts in tpe.map(get_concepts, paper_sections)\n",
    "            for concept in concepts\n",
    "        ]\n",
    "    return merge_concepts(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26c1d98-189f-477e-a6dc-0819b2f5d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_prereqs = get_all_concepts(paper_sections)\n",
    "# paper_prereqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68289859-d23c-433a-88c0-e06da348ee82",
   "metadata": {},
   "source": [
    "# 3. Create Video Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f023b262-18f4-4fd9-982d-680f832c4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create video script\n",
    "def get_script_for_concepts(concepts):\n",
    "    chat = Chat(f'''Given the following prerequisite concepts needed to understand a scientific paper, write a script for a video that explains them in an intuitive way.\n",
    "Assume there's two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each character's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: Hello everyone.\n",
    "{SPEAKER_NAMES[1]}: Indeed, hello!\n",
    "Do not include any other script syntax.\n",
    "Do not include a conclusion.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    text = chat.message(str(concepts), model=MODEL)\n",
    "    return text\n",
    "\n",
    "def get_script_for_paper_section(paper_section):\n",
    "    chat = Chat(f'''Given the following section of a scientific paper, write an educational script for a video that explains this in an intuitive way.\n",
    "Assume there's two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each character's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: Hello everyone.\n",
    "{SPEAKER_NAMES[1]}: Indeed, hello!\n",
    "Do not include any other script syntax.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    text = chat.message(str(paper_section), model=MODEL)\n",
    "    return text\n",
    "\n",
    "def get_entire_script(paper_prereqs, paper_sections, consolidate=False):\n",
    "    all_scripts = [None] * (1+len(paper_sections))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max(MAX_WORKERS//2, 1)) as tpe:\n",
    "        runs = []\n",
    "        if paper_prereqs:\n",
    "            runs.append(tpe.submit(get_script_for_concepts, paper_prereqs))\n",
    "        runs.extend([tpe.submit(get_script_for_paper_section, section) for section in paper_sections])\n",
    "        for i, r in enumerate(concurrent.futures.as_completed(runs)):\n",
    "            ridx = runs.index(r)\n",
    "            all_scripts[ridx] = r.result()\n",
    "            logger.info(f'Done with {i} / {len(runs)}')\n",
    "    if consolidate:\n",
    "        all_scripts = flatten_list(all_scripts)\n",
    "        chat = Chat(f'''Consolidate the following scripts that go over a scientific paper in an intuitive way.\n",
    "Make it less redundant, more fun, and only include one intro and outro.\n",
    "Assume there's two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each character's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: Hello everyone.\n",
    "{SPEAKER_NAMES[1]}: Indeed, hello!\n",
    "Do not include any other script syntax.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "        text = chat.message(str(all_scripts), model=MODEL)\n",
    "        all_scripts = [text]\n",
    "    return all_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe0140d-014a-499e-af73-7819e0b3e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_script = get_entire_script(paper_prereqs, paper_sections)\n",
    "# len(paper_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee8417-bb54-462d-aed4-3c013648d74b",
   "metadata": {},
   "source": [
    "# 4. Video images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "253e65e2-5f1e-46dc-b8ef-9b046f92d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "class RateLimited:\n",
    "    def __init__(self, max_per_minute):\n",
    "        self.max_per_minute = max_per_minute\n",
    "        self.current_minute = time.strftime('%M')\n",
    "        self.lock = threading.Lock()\n",
    "        self.calls = 0\n",
    "\n",
    "    def __call__(self, fn):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            run = False\n",
    "            with self.lock:\n",
    "                current_minute = time.strftime('%M')\n",
    "                if current_minute != self.current_minute:\n",
    "                    self.current_minute = current_minute\n",
    "                    self.calls = 0\n",
    "                if self.calls < self.max_per_minute:\n",
    "                    self.calls += 1\n",
    "                    run = True\n",
    "            if run:\n",
    "                return fn(*args, **kwargs)\n",
    "            else:\n",
    "                time.sleep(15)\n",
    "                return wrapper(*args, **kwargs)\n",
    "                    \n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6901a7b8-57a0-4c2c-808d-fcd617854f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIImage:\n",
    "    class Size(enum.Enum):\n",
    "        LARGE = \"1024x1024\"\n",
    "        LONG  = \"1792x1024\"\n",
    "        WIDE =  \"1024x1792\"\n",
    "\n",
    "    @classmethod\n",
    "    @RateLimited(12)\n",
    "    @retry_with_logging()\n",
    "    def create(cls, prompt, n=1, size=Size.WIDE):\n",
    "        logger.info(f'asking openai.image {prompt}')\n",
    "        resp = openai.OpenAI(api_key=openai.api_key).images.generate(prompt=prompt, n=n, size=size.value, model=\"dall-e-3\", response_format='b64_json', timeout=45)\n",
    "        logger.info('received openai.Image...')\n",
    "        return resp.data[0].b64_json\n",
    "\n",
    "\n",
    "replicate_api_key = open('/Users/jong/.replicate_apikey').read().strip()\n",
    "class FofrAIImage:\n",
    "    @classmethod\n",
    "    @RateLimited(12)\n",
    "    @retry_with_logging()\n",
    "    def create(cls, prompt, n=1, response_format=\"url\", model=\"fofr\", size=\"512x896\"):\n",
    "        logger.info(f'requesting FOFR Image with prompt={prompt}, n={n}, response_format={response_format}, model={model}, size={size}...')\n",
    "        width, height = size.split('x')\n",
    "        width, height = int(width), int(height)\n",
    "        resp = requests.post(\n",
    "            \"https://api.replicate.com/v1/predictions\",\n",
    "            headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Token {replicate_api_key}\"},\n",
    "            json={\"version\": \"a83d4056c205f4f62ae2d19f73b04881db59ce8b81154d314dd34ab7babaa0f1\", \"input\": {\n",
    "                \"prompt\": prompt,\n",
    "                \"width\": width, \"height\": height,\n",
    "                \"num_images\": n,\n",
    "            }},\n",
    "        )\n",
    "        resp = resp.json()\n",
    "        sleeps = 0\n",
    "        while resp.get(\"status\", \"fail\").lower() not in {\"fail\", \"succeeded\"}:\n",
    "            if sleeps >= 10:\n",
    "                raise Exception('Error generating image', resp)\n",
    "            logger.info(f\"Sleeping 1...\")\n",
    "            time.sleep(1)\n",
    "            sleeps += 1\n",
    "            resp = requests.get(f\"https://api.replicate.com/v1/predictions/{resp['id']}\", headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Token {replicate_api_key}\"})\n",
    "            resp = resp.json()\n",
    "        logger.info('received Image...')\n",
    "        url = resp['output'][0]\n",
    "        # Encode to base64 and format as a data URI\n",
    "        return base64.b64encode(requests.get(url).content).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5b008a8-c095-4f2e-afde-87ec9bcf125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.open(io.BytesIO(base64.b64decode(FofrAIImage.create('cute snail on a park bench'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2be2605-93a8-48c6-95f1-658e9e3f6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry_with_logging()\n",
    "def get_image_from_text(sentence):\n",
    "    chat = Chat(f'''Given\n",
    "the following sentence in a script, write a concise description of an image to display while this script is read.\n",
    "Only write the short description and nothing else.\n",
    "Do not include specific numbers or the character names.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    prompt = chat.message(sentence, model=MODEL)\n",
    "    # img = AIImage.create(prompt)\n",
    "    img = FofrAIImage.create(prompt)\n",
    "    return sentence, img, prompt\n",
    "\n",
    "def get_images_from_text(text):\n",
    "    sentences = text.split('\\n')\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max(MAX_WORKERS//2, 1)) as tpe:\n",
    "        runs = []\n",
    "        for sentence in sentences:\n",
    "            if not sentence:\n",
    "                continue\n",
    "            runs.append(tpe.submit(get_image_from_text, sentence))\n",
    "        images = [None] * len(runs)\n",
    "        for r in concurrent.futures.as_completed(runs):\n",
    "            ridx = runs.index(r)\n",
    "            images[ridx] = r.result()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12a2af5b-eb80-4126-8672-219f40f246ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = get_images_from_text(paper_prereqs_script)\n",
    "# len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f004ccd5-9ab4-4c3a-a1f8-de67083d5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for txt, img, prompt in images:\n",
    "#     img = PIL.Image.open(io.BytesIO(base64.b64decode(img[\"b64_json\"])))\n",
    "#     IPython.display.display(txt)\n",
    "#     IPython.display.display(prompt)\n",
    "#     IPython.display.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9319449c-0e4e-4d36-8de9-d73e297978bd",
   "metadata": {},
   "source": [
    "# 5. Audio: Script to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98cbeb95-f921-4805-99f7-1c73856a1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaker_sentence(sentence, names):\n",
    "    for name in names:\n",
    "        if sentence.startswith(f'{name}:'):\n",
    "            return name, sentence[len(f'{name}:')+1:]\n",
    "    return names[0], sentence\n",
    "\n",
    "def script2speech(sentences, names, voices):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as tpe:\n",
    "        jobs = []\n",
    "        for sentence in sentences:\n",
    "            speaker, sentence = speaker_sentence(sentence, names)\n",
    "            jobs.append(tpe.submit(voices[names.index(speaker)].tts, sentence))\n",
    "        audios = [b''] * len(jobs)\n",
    "        for future in concurrent.futures.as_completed(jobs):\n",
    "            idx = jobs.index(future)\n",
    "            audios[idx] = future.result()\n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79197362-029b-470a-af22-f8fcfff3d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audios = script2speech([x[0] for x in images], SPEAKER_NAMES, SPEAKER_VOICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0deee6af-afc5-48fc-a2c2-65fbcfd1c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython.display.Audio(audios[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b77490-3ec0-419e-99c9-f8e153a6a045",
   "metadata": {},
   "source": [
    "# 6. Join audio and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "531cbc42-4126-4ec4-a4d9-bac70b31956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_videos(directory, output_file):\n",
    "    # get list of video files in directory\n",
    "    files = sorted([f for f in os.listdir(directory) if f.endswith(\".mp4\")], key=lambda x: int(x.split('.mp4')[0].split('_')[1]))\n",
    "\n",
    "    # create a file that contains the list of all video files\n",
    "    filenames_f = f'{directory}/_files.txt'\n",
    "    with open(filenames_f, 'w') as f:\n",
    "        for video_file in files:\n",
    "            f.write(f\"file '{directory}/{video_file}'\\n\")\n",
    "\n",
    "    # concatenate all videos using FFmpeg\n",
    "    command = f\"ffmpeg -f concat -safe 0 -i {filenames_f} -c copy {output_file}\"\n",
    "    print(command)\n",
    "    try:\n",
    "        os.remove(output_file)\n",
    "    except:\n",
    "        pass\n",
    "    subprocess.check_call(command, shell=True, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "def process_one_clip(tmpdir, i, img, audio):\n",
    "    # Convert audio bytes to pydub's AudioSegment\n",
    "    # audio_segment = AudioSegment.from_file(io.BytesIO(audio))\n",
    "    audio_path = f'{tmpdir}/audio_{i}.mp3'\n",
    "    with open(audio_path, 'wb') as f:\n",
    "        f.write(audio)\n",
    "    # audio_segment.export(audio_path)\n",
    "    audio_segment = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # Create an ImageClip for this image and audio, with duration matching the audio\n",
    "    duration = len(audio_segment) / 1000.0  # AudioSegment.length is in milliseconds\n",
    "    # Convert PIL Image to numpy array\n",
    "    np_image = np.array(img)\n",
    "    video_clip = ImageClip(np_image, duration=duration)\n",
    "    video_clip.fps = 30\n",
    "    video_clip = video_clip.set_audio(AudioFileClip(audio_path))\n",
    "    video_clip.write_videofile(\n",
    "        f\"{tmpdir}/clip_{i:0>3}.mp4\", codec='libx264', audio_codec='aac',\n",
    "        temp_audiofile=f'temp-audio-{i}.m4a', remove_temp=True,\n",
    "        verbose=False, logger=None,\n",
    "    )\n",
    "\n",
    "def create_video(images, audios, outpath):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        process_one = functools.partial(process_one_clip, tmpdir)\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as tpe:\n",
    "            for i, _ in enumerate(tpe.map(process_one, range(len(images)), images, audios)):\n",
    "                logger.info(f'Done with {i} / {len(images)}')\n",
    "        # Concatenate all video clips\n",
    "        concatenate_videos(tmpdir, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5258b3b3-2cf4-4b72-962e-f27534d3c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpath = '/Users/jong/Downloads/Cell_20230725/final_video.mp4'\n",
    "# create_video([PIL.Image.open(io.BytesIO(base64.b64decode(img[1][\"b64_json\"]))) for img in images], audios, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d20726c-3fd1-4539-a782-3f954d007140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    def __init__(self, paper_path, outpath, skip_prereqs=False):\n",
    "        self.paper_path = paper_path\n",
    "        self.outpath = outpath\n",
    "        self.skip_prereqs = skip_prereqs\n",
    "\n",
    "    def run(self, script=None):\n",
    "        if script is None:\n",
    "            self.paper_text = extract_text_from_pdf(self.paper_path)\n",
    "            self.paper_sections = text_into_token_chunks(self.paper_text, smoothing=3)\n",
    "            if self.skip_prereqs:\n",
    "                self.paper_prereqs = None\n",
    "            else:\n",
    "                self.paper_prereqs = get_all_concepts(self.paper_sections)\n",
    "            self.paper_script = get_entire_script(self.paper_prereqs, self.paper_sections)\n",
    "        else:\n",
    "            self.paper_script = script\n",
    "    \n",
    "        def process_one_part(script):\n",
    "            images = get_images_from_text(script)\n",
    "            audios = script2speech([x[0] for x in images], SPEAKER_NAMES, SPEAKER_VOICES)\n",
    "            return images, audios\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as tpe:\n",
    "            runs = [tpe.submit(process_one_part, script) for script in self.paper_script if script]\n",
    "            images, audios = [None] * len(runs), [None] * len(runs)\n",
    "            for i, r in enumerate(concurrent.futures.as_completed(runs)):\n",
    "                ridx = runs.index(r)\n",
    "                imgs, auds = r.result()\n",
    "                images[ridx], audios[ridx] = imgs, auds\n",
    "                logger.info(f'Got images and audio for {i} / {len(runs)}')\n",
    "    \n",
    "        self.images = flatten_list(images)\n",
    "        self.audios = flatten_list(audios)\n",
    "        create_video([PIL.Image.open(io.BytesIO(base64.b64decode(img))) for _txt, img, _prompt in self.images], self.audios, self.outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dbe0973-4207-42fd-9e35-a9b348e983b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-15T00:07:08.141375Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=9089 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145538375680\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-6_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:08.142700Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145538375680\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-6_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.210156Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145538375680\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-6_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.211101Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 0 / 1               \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.214545Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=95 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.215058Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=104 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.215752Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=114 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.216006Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.216082Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=103 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.217032Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.218034Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:30.226509Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.431930Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.435187Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A serene forest scene with rows of crops and trees in various stages of growth, representing the cyclical nature of agricultural and forestry processes., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.489534Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.490297Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A classroom setting with an instructor standing at the front, lecturing about economics or finance concepts., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.610630Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.611400Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=An image depicting mathematical equations related to expected values, profit rates, and spot return rates, possibly showing the concepts of path-independence and path-dependence., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.683558Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.684377Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A mathematical equation or economic model visualized through abstract shapes, lines, and symbols representing concepts like capital, returns, and economic cycles or growth paths., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.699394Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:31.756266Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:32.007089Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:32.103966Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:32.841820Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:32.871852Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:32.989365Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=105 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:32.991475Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:33.199706Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:33.201982Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:33.985879Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:34.118373Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=97 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:34.119978Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:34.303803Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:34.683671Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:34.702268Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:34.703339Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A financial graph or chart depicting cash flows and investment analysis concepts like internal rate of return (IRR) and changes in capitalization over time., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.225241Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.455560Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.632096Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=96 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.632875Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.842275Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.973116Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=104 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:35.973843Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:36.144162Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:36.145019Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A graph or chart showing curves representing the expected rate of return on capital and the internal rate of return (IRR) over different phases of a growth cycle, with their maximum values occurring at distinct points., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:36.333488Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:36.335901Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:37.499794Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:37.832286Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.040758Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=105 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.041482Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.232390Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.233210Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A line graph or chart displaying finance or investment data, potentially showing the relationship between rotation cycle length and return on equity, contrasted with net present value calculations under different market interest rates or discount rates., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.338610Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.643153Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.643901Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A concise image description for this script sentence:\n",
      "\n",
      "A financial chart or graph showing different investment analysis metrics and their diverging paths or values over time., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:38.917063Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.061055Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCurrently at self.num_tokens_from_messages(self._history)=95 tokens in conversation\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.061711Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting chatcompletion model='AWS/claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.071910Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.425153Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.426976Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A simple graphic display representing business concepts like rate of return, net present value calculations, and investment decision factors., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.730065Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145605533696\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_3\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:39.892542Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:40.298779Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived chatcompletion model='claude-3-haiku'...\u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:40.299599Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting FOFR Image with prompt=A line graph illustrating the concept of path-dependent rates of return and capital appreciation over time., n=1, response_format=url, model=fofr, size=512x896...\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:40.434512Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:40.533750Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:41.037973Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:41.612610Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSleeping 1...                 \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:41.764518Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145571954688\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_1\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:42.576274Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145555165184\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_0\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:42.746975Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived Image...             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145588744192\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-8_2\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:43.549230Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 0 / 1\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:50.343303Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 0 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.654341Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 1 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.656085Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 2 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.656895Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 3 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.657614Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 4 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.658276Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 5 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.659850Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 6 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:52.660730Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 7 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:54.646960Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 8 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2024-03-15T00:07:54.652179Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 9 / 10              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "ffmpeg -f concat -safe 0 -i /var/folders/kx/xrqgq16n2yn81hvm8wgy8d440000gr/T/tmph5hup19_/_files.txt -c copy /Users/jong/Downloads/Path-dependency_of_capital_return_in_periodic_growth_processes.mp4\n",
      "CPU times: user 6.85 s, sys: 3.25 s, total: 10.1 s\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SPEAKER_NAMES = ['Jerry', 'George'][::-1]\n",
    "# adjectives = 'intuitive, educational, and funny'\n",
    "# style = ' in the style of a hilarious conversation between Jerry Seinfeld and George Costanza'\n",
    "# title = \"\"\"Title: Navigating MLR Model Evaluation - Mastering Hypothesis Tests in Multiple Regression!\n",
    "# \"\"\"\n",
    "# chat = Chat(f'''Turn a video's info into a long script{style}.\n",
    "# Make it {adjectives}.\n",
    "# There are two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "# Prefix each speaker's lines with their name and a :, like the following.\n",
    "# {SPEAKER_NAMES[0]}: \n",
    "# {SPEAKER_NAMES[1]}: \n",
    "# Do not include any other script syntax.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "# text = chat.message(\n",
    "#     title,\n",
    "#     model=MODEL,\n",
    "# )\n",
    "paper_path = '/Users/jong/Downloads/Path-dependency of capital return in periodic growth processes.pdf'\n",
    "outpath = paper_path[:-4].replace(' ', '_') + '.mp4'\n",
    "MAX_WORKERS = 8\n",
    "runner = Runner(paper_path, outpath, skip_prereqs=True)\n",
    "# runner.run(script=[x for x in text.split('\\n') if x])\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b2058fa-75be-4b73-ab77-7d75d929fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone! Today we will be discussing the path-dependency of capital return in periodic growth processes. This is a fascinating and complex topic, so let's break it down step-by-step.\n",
      "Absolutely, let's start with the basics. In periodic growth processes like forestry or agriculture, profits often accumulate within a rotation period. The expected value of the profit rate does not directly depend on divestments or the capitalization path. \n",
      "That's right. The expected value of the profit rate is path-independent and depends on the time-average of the spot return rates, as shown in Equation 8. However, an interesting finding is that the expected value of capitalization is path-dependent, as seen in Equation 9.\n",
      "Exactly! This path-dependency of capitalization leads to the path-dependency of the rate of return on capital, according to Equation 3. So, the sequence of return rates within the growth cycle affects the overall return on capital.\n",
      "Yes, and this is quite different from the internal rate of return (IRR), which is path-independent according to Equation 11. The IRR only depends on the amount and timing of cash flows, not the intermediate changes in capitalization.\n",
      "That's a great point. Figure 1 illustrates this difference between the expected rate of return on capital and the IRR. We can see that their maximum values occur at different phases of the growth cycle.\n",
      "Absolutely. This means that optimizing based on the rate of return on capital would lead to different management decisions compared to optimizing based on the IRR. It's an important distinction in periodic growth processes.\n",
      "Indeed, and another notable finding is that the rotation cycle length maximizing the return on equity is independent of market interest rates, as shown in Figure 3. This contrasts with the net present value approach, which heavily depends on the discount rate.\n",
      "Yes, that's a crucial difference. The net present value approach is focused on maximizing consumption utility, while the rate of return on capital is concerned with wealth accumulation. This leads to different implications for leveraging and the role of market interest rates.\n",
      "Precisely. The path-dependency of the rate of return on capital and its independence from market interest rates make it a powerful tool for managing periodic growth processes where capital appreciation is the goal.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([t.split(': ', maxsplit=1)[1] for t, *_ in runner.images]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dffaf5d7-f5ec-4c99-91ac-8224f09fceb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # paper_path = '/Users/jong/Downloads/covid_garbage.pdf'\n",
    "# paper_path  = '/Users/jong/Downloads/2311.02745.pdf'\n",
    "# outpath = (paper_path[:-4] + '.mp4').replace(' ', '_')\n",
    "# MAX_WORKERS = 8\n",
    "# runner = Runner(paper_path, outpath, skip_prereqs=True)\n",
    "# runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b64fd3af-13d5-4065-b1e7-b10e9ce0debd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for txt, img, prompt in runner.images:\n",
    "#     img = PIL.Image.open(io.BytesIO(base64.b64decode(img)))\n",
    "#     IPython.display.display(txt)\n",
    "#     IPython.display.display(prompt)\n",
    "#     IPython.display.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c840a28c-288c-4921-a445-4f83c64d511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_video([PIL.Image.open(io.BytesIO(base64.b64decode(img))) for _txt, img, _prompt in runner.images], runner.audios, runner.outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ec6ac-96e0-4ccf-8117-8e245c45d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613af4e1-15f8-45ad-bf87-c285f25be7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
