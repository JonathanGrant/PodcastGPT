{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987e1c5d-936a-4a35-bde2-cd01028340dd",
   "metadata": {},
   "source": [
    "# Idea is to take a paper / pdf and convert it to a lecture that explains it intuitively.\n",
    "\n",
    "### Steps:\n",
    "1. Download PDF and get text\n",
    "2. Ask ChatGPT what concepts (in order) need to be understood to understand the paper\n",
    "3. Create video Script\n",
    "4. Create video images\n",
    "5. Add audio on top of images\n",
    "6. Join and done\n",
    "\n",
    "### What to display in video?\n",
    "* Ask Chat for slide text (md format or something) given a paragraph\n",
    "\n",
    "### Video Outline:\n",
    "1. Concepts / Building blocks\n",
    "2. Paper summary\n",
    "3. Each part of the paper (ask Chat for parts)\n",
    "4. Conclusion and Implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee88f59f-565b-47d4-9327-2e0b5f14d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatPodcastGPT import Chat, PodcastChat, OpenAITTS\n",
    "import collections\n",
    "import concurrent.futures\n",
    "import os\n",
    "import feedparser\n",
    "import structlog\n",
    "import itertools\n",
    "import enum\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import PyPDF2\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import retrying\n",
    "import openai\n",
    "import random\n",
    "import IPython.display\n",
    "import datetime\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "import base64\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "import numpy as np\n",
    "import io\n",
    "import subprocess\n",
    "import os\n",
    "import functools\n",
    "import logging\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import threading\n",
    "import traceback\n",
    "import inspect\n",
    "\n",
    "\n",
    "# MODEL = 'gpt-3.5-turbo-16k'\n",
    "MODEL = 'gpt-4-1106-preview'\n",
    "MAX_TOKENS = 120_000\n",
    "# MAX_TOKENS = 2_000\n",
    "JOIN_NUM_DEFAULT = 300\n",
    "SPEAKER_NAMES = ['Alfred', 'Alice']\n",
    "SPEAKER_VOICES = [OpenAITTS(OpenAITTS.MAN), OpenAITTS(OpenAITTS.WOMAN)]\n",
    "MAX_WORKERS = 4\n",
    "flatten_list = lambda a: list(itertools.chain(*[x for x in a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db918fd1-d558-4fab-83c6-4f1cbd0f5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_thread_id(logger, log_method, event_dict):\n",
    "    \"\"\"\n",
    "    Add the thread ID to the event_dict if the current execution is within a thread.\n",
    "    \"\"\"\n",
    "    if threading.current_thread() != threading.main_thread():\n",
    "        event_dict[\"thread_id\"] = threading.get_ident()\n",
    "        event_dict[\"thread_name\"] = threading.current_thread().name\n",
    "    else:\n",
    "        event_dict[\"thread_id\"] = \"[Main]\"\n",
    "    return event_dict\n",
    "\n",
    "# Configure structlog\n",
    "structlog.configure(\n",
    "    processors=[\n",
    "        structlog.stdlib.add_log_level,\n",
    "        structlog.stdlib.add_logger_name,\n",
    "        add_thread_id,\n",
    "        structlog.stdlib.PositionalArgumentsFormatter(),\n",
    "        structlog.processors.TimeStamper(fmt=\"iso\"),\n",
    "        structlog.dev.ConsoleRenderer()\n",
    "    ],\n",
    "    context_class=dict,\n",
    "    logger_factory=structlog.stdlib.LoggerFactory(),\n",
    "    wrapper_class=structlog.stdlib.BoundLogger,\n",
    "    cache_logger_on_first_use=True,\n",
    ")\n",
    "logging.getLogger('moviepy').setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(stream=sys.stdout, format=\"%(message)s\", level=logging.INFO)\n",
    "logger = structlog.get_logger(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7f8372-dd4c-4c50-8e1d-be8fcb4a620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-11-10T16:25:23.712777Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mhello                         \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d9ef8a-c9f9-43b0-bbdf-951b8b641d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_exception(exception, func_name):\n",
    "    \"\"\"Log the exception with its stack trace and the function name.\"\"\"\n",
    "    stack_trace = traceback.format_exc()\n",
    "    logger.error(f\"Exception in {func_name}: {exception}\\n{stack_trace}\")\n",
    "    return True\n",
    "\n",
    "def retry_with_logging(stop_max_attempt_number=5, wait_fixed=2000):\n",
    "    def decorator(func):\n",
    "        @retrying.retry(stop_max_attempt_number=stop_max_attempt_number, wait_fixed=wait_fixed,\n",
    "               retry_on_exception=lambda exception: log_exception(exception, func.__name__))\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459e615-25d1-48f5-8e8c-d02b0e527716",
   "metadata": {},
   "source": [
    "## 1. PDF to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f5cfcc-d760-46be-b589-07548d97f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "        text = ''\n",
    "        for page_number in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_number]\n",
    "            text += page.extract_text()\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966042dc-f97a-49a4-9a5e-beff09e3a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_path = '/Users/jong/Downloads/covid_garbage.pdf'\n",
    "# paper_text = extract_text_from_pdf(paper_path)\n",
    "# len(paper_text), paper_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b71680-46d5-4ac6-94c1-61bd12fae9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_into_token_chunks(text, max_tokens=MAX_TOKENS, smoothing=0):\n",
    "    \"\"\"Split the text into parts based on tokens.\"\"\"\n",
    "    sentences = text.replace('\\n', '').split(\".\")\n",
    "    all_parts = []\n",
    "    current_part = []\n",
    "    for sentence in sentences:\n",
    "        current_part.append(sentence + '.')\n",
    "        if Chat.num_tokens_from_text(' '.join(current_part)) > max_tokens:\n",
    "            part_text = ' '.join(current_part[:-1])\n",
    "            all_parts.append(part_text)\n",
    "            current_part = current_part[-(smoothing+1):]\n",
    "\n",
    "    if current_part:\n",
    "        all_parts.append(' '.join(current_part[:-1]))\n",
    "    return all_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8cf0cc9-981e-434a-9b81-4846bbd6748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_sections = text_into_token_chunks(paper_text, smoothing=3)\n",
    "# len(paper_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea69d579-66b1-4fa7-9aaf-803910932cef",
   "metadata": {},
   "source": [
    "# 2. Concepts needed for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a7e891-3362-43dc-9a53-e5c22bb603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def help_load_json(txt):\n",
    "    if txt.startswith(\"```json\\n\"):\n",
    "        return txt.split(\"```json\\n\", maxsplit=1)[1].rsplit(\"```\")[0]\n",
    "    return txt\n",
    "\n",
    "@retry_with_logging()\n",
    "def get_concepts(paper_section):\n",
    "    chat = Chat('''Given some text from a scientific journal, return a JSON formatted list containing a few prerequisite concepts needed for understanding the paper.\n",
    "Respond only a JSON list and nothing else.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    resp = chat.message(paper_section, model=MODEL)\n",
    "    try:\n",
    "        data = json.loads(help_load_json(resp))\n",
    "        assert isinstance(data, list)\n",
    "    except:\n",
    "        logger.critical(f\"get_concepts Cannot parse resp: {resp}\")\n",
    "        raise\n",
    "    return data\n",
    "\n",
    "@retry_with_logging()\n",
    "def merge_concepts(concepts):\n",
    "    if len(concepts) <= 6:\n",
    "        return concepts\n",
    "    chat = Chat('''Given a list of concepts needed to understand a paper, reduce them to just 5 or fewer prerequisite concepts.\n",
    "Only respond as a valid JSON list, and nothing else. Order the list from least to most complex.'''.replace('\\n', ' '))\n",
    "    resp = chat.message(str(concepts), model=MODEL)\n",
    "    try:\n",
    "        data = json.loads(help_load_json(resp))\n",
    "        assert isinstance(data, list)\n",
    "    except:\n",
    "        logger.critical(f\"merge_concepts Cannot parse resp: {resp}\")\n",
    "        raise\n",
    "    assert isinstance(data, list)\n",
    "    return data\n",
    "\n",
    "def get_all_concepts(paper_sections):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max(MAX_WORKERS//4, 1)) as tpe:\n",
    "        concepts = [\n",
    "            concept\n",
    "            for concepts in tpe.map(get_concepts, paper_sections)\n",
    "            for concept in concepts\n",
    "        ]\n",
    "    return merge_concepts(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26c1d98-189f-477e-a6dc-0819b2f5d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_prereqs = get_all_concepts(paper_sections)\n",
    "# paper_prereqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68289859-d23c-433a-88c0-e06da348ee82",
   "metadata": {},
   "source": [
    "# 3. Create Video Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f023b262-18f4-4fd9-982d-680f832c4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create video script\n",
    "def get_script_for_concepts(concepts):\n",
    "    chat = Chat(f'''Given the following prerequisite concepts needed to understand a scientific paper, write a script for a video that explains them in an intuitive way.\n",
    "Assume there's two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each character's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: Hello everyone.\n",
    "{SPEAKER_NAMES[1]}: Indeed, hello!\n",
    "Do not include any other script syntax.\n",
    "Do not include a conclusion.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    text = chat.message(str(concepts), model=MODEL)\n",
    "    return text\n",
    "\n",
    "def get_script_for_paper_section(paper_section):\n",
    "    chat = Chat(f'''Given the following section of a scientific paper, write an educational script for a video that explains this in an intuitive way.\n",
    "Assume there's two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each character's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: Hello everyone.\n",
    "{SPEAKER_NAMES[1]}: Indeed, hello!\n",
    "Do not include any other script syntax.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    text = chat.message(str(paper_section), model=MODEL)\n",
    "    return text\n",
    "\n",
    "def get_entire_script(paper_prereqs, paper_sections, consolidate=False):\n",
    "    all_scripts = [None] * (1+len(paper_sections))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max(MAX_WORKERS//2, 1)) as tpe:\n",
    "        runs = []\n",
    "        if paper_prereqs:\n",
    "            runs.append(tpe.submit(get_script_for_concepts, paper_prereqs))\n",
    "        runs.extend([tpe.submit(get_script_for_paper_section, section) for section in paper_sections])\n",
    "        for i, r in enumerate(concurrent.futures.as_completed(runs)):\n",
    "            ridx = runs.index(r)\n",
    "            all_scripts[ridx] = r.result()\n",
    "            logger.info(f'Done with {i} / {len(runs)}')\n",
    "    if consolidate:\n",
    "        all_scripts = flatten_list(all_scripts)\n",
    "        chat = Chat(f'''Consolidate the following scripts that go over a scientific paper in an intuitive way.\n",
    "Make it less redundant, more fun, and only include one intro and outro.\n",
    "Assume there's two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each character's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: Hello everyone.\n",
    "{SPEAKER_NAMES[1]}: Indeed, hello!\n",
    "Do not include any other script syntax.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "        text = chat.message(str(all_scripts), model=MODEL)\n",
    "        all_scripts = [text]\n",
    "    return all_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe0140d-014a-499e-af73-7819e0b3e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_script = get_entire_script(paper_prereqs, paper_sections)\n",
    "# len(paper_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee8417-bb54-462d-aed4-3c013648d74b",
   "metadata": {},
   "source": [
    "# 4. Video images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "253e65e2-5f1e-46dc-b8ef-9b046f92d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "class RateLimited:\n",
    "    def __init__(self, max_per_minute):\n",
    "        self.max_per_minute = max_per_minute\n",
    "        self.current_minute = time.strftime('%M')\n",
    "        self.lock = threading.Lock()\n",
    "        self.calls = 0\n",
    "\n",
    "    def __call__(self, fn):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            run = False\n",
    "            with self.lock:\n",
    "                current_minute = time.strftime('%M')\n",
    "                if current_minute != self.current_minute:\n",
    "                    self.current_minute = current_minute\n",
    "                    self.calls = 0\n",
    "                if self.calls < self.max_per_minute:\n",
    "                    self.calls += 1\n",
    "                    run = True\n",
    "            if run:\n",
    "                return fn(*args, **kwargs)\n",
    "            else:\n",
    "                time.sleep(15)\n",
    "                return wrapper(*args, **kwargs)\n",
    "                    \n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6901a7b8-57a0-4c2c-808d-fcd617854f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIImage:\n",
    "    class Size(enum.Enum):\n",
    "        LARGE = \"1024x1024\"\n",
    "        LONG  = \"1792x1024\"\n",
    "\n",
    "    @classmethod\n",
    "    @RateLimited(12)\n",
    "    @retry_with_logging()\n",
    "    def create(cls, prompt, n=1, size=Size.LARGE):\n",
    "        logger.info(f'asking openai.image {prompt}')\n",
    "        resp = openai.OpenAI(api_key=openai.api_key).images.generate(prompt=prompt, n=n, size=size.value, model=\"dall-e-3\", response_format='b64_json', timeout=45)\n",
    "        logger.info('received openai.Image...')\n",
    "        return resp.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b008a8-c095-4f2e-afde-87ec9bcf125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.open(io.BytesIO(base64.b64decode(AIImage.create('cute snail on a park bench'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2be2605-93a8-48c6-95f1-658e9e3f6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry_with_logging()\n",
    "def get_image_from_text(sentence):\n",
    "    chat = Chat(f'''Given\n",
    "the following sentence in a script, write a concise description of an image to display while this script is read.\n",
    "Only write the short description and nothing else.\n",
    "Do not include specific numbers or the character names.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "    prompt = chat.message(sentence, model=MODEL)\n",
    "    img = AIImage.create(prompt)\n",
    "    return sentence, img, prompt\n",
    "\n",
    "def get_images_from_text(text):\n",
    "    sentences = text.split('\\n')\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max(MAX_WORKERS//2, 1)) as tpe:\n",
    "        runs = []\n",
    "        for sentence in sentences:\n",
    "            if not sentence:\n",
    "                continue\n",
    "            runs.append(tpe.submit(get_image_from_text, sentence))\n",
    "        images = [None] * len(runs)\n",
    "        for r in concurrent.futures.as_completed(runs):\n",
    "            ridx = runs.index(r)\n",
    "            images[ridx] = r.result()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a2af5b-eb80-4126-8672-219f40f246ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = get_images_from_text(paper_prereqs_script)\n",
    "# len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f004ccd5-9ab4-4c3a-a1f8-de67083d5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for txt, img, prompt in images:\n",
    "#     img = PIL.Image.open(io.BytesIO(base64.b64decode(img[\"b64_json\"])))\n",
    "#     IPython.display.display(txt)\n",
    "#     IPython.display.display(prompt)\n",
    "#     IPython.display.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9319449c-0e4e-4d36-8de9-d73e297978bd",
   "metadata": {},
   "source": [
    "# 5. Audio: Script to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98cbeb95-f921-4805-99f7-1c73856a1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaker_sentence(sentence, names):\n",
    "    for name in names:\n",
    "        if sentence.startswith(f'{name}:'):\n",
    "            return name, sentence[len(f'{name}:')+1:]\n",
    "    return names[0], sentence\n",
    "\n",
    "def script2speech(sentences, names, voices):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as tpe:\n",
    "        jobs = []\n",
    "        for sentence in sentences:\n",
    "            speaker, sentence = speaker_sentence(sentence, names)\n",
    "            jobs.append(tpe.submit(voices[names.index(speaker)].tts, sentence))\n",
    "        audios = [b''] * len(jobs)\n",
    "        for future in concurrent.futures.as_completed(jobs):\n",
    "            idx = jobs.index(future)\n",
    "            audios[idx] = future.result()\n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79197362-029b-470a-af22-f8fcfff3d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audios = script2speech([x[0] for x in images], SPEAKER_NAMES, SPEAKER_VOICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0deee6af-afc5-48fc-a2c2-65fbcfd1c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython.display.Audio(audios[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b77490-3ec0-419e-99c9-f8e153a6a045",
   "metadata": {},
   "source": [
    "# 6. Join audio and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531cbc42-4126-4ec4-a4d9-bac70b31956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_videos(directory, output_file):\n",
    "    # get list of video files in directory\n",
    "    files = sorted([f for f in os.listdir(directory) if f.endswith(\".mp4\")], key=lambda x: int(x.split('.mp4')[0].split('_')[1]))\n",
    "\n",
    "    # create a file that contains the list of all video files\n",
    "    filenames_f = f'{directory}/_files.txt'\n",
    "    with open(filenames_f, 'w') as f:\n",
    "        for video_file in files:\n",
    "            f.write(f\"file '{directory}/{video_file}'\\n\")\n",
    "\n",
    "    # concatenate all videos using FFmpeg\n",
    "    command = f\"ffmpeg -f concat -safe 0 -i {filenames_f} -c copy {output_file}\"\n",
    "    print(command)\n",
    "    try:\n",
    "        os.remove(output_file)\n",
    "    except:\n",
    "        pass\n",
    "    subprocess.check_call(command, shell=True, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "def process_one_clip(tmpdir, i, img, audio):\n",
    "    # Convert audio bytes to pydub's AudioSegment\n",
    "    # audio_segment = AudioSegment.from_file(io.BytesIO(audio))\n",
    "    audio_path = f'{tmpdir}/audio_{i}.mp3'\n",
    "    with open(audio_path, 'wb') as f:\n",
    "        f.write(audio)\n",
    "    # audio_segment.export(audio_path)\n",
    "    audio_segment = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # Create an ImageClip for this image and audio, with duration matching the audio\n",
    "    duration = len(audio_segment) / 1000.0  # AudioSegment.length is in milliseconds\n",
    "    # Convert PIL Image to numpy array\n",
    "    np_image = np.array(img)\n",
    "    video_clip = ImageClip(np_image, duration=duration)\n",
    "    video_clip.fps = 30\n",
    "    video_clip = video_clip.set_audio(AudioFileClip(audio_path))\n",
    "    video_clip.write_videofile(\n",
    "        f\"{tmpdir}/clip_{i:0>3}.mp4\", codec='libx264', audio_codec='aac',\n",
    "        temp_audiofile=f'temp-audio-{i}.m4a', remove_temp=True,\n",
    "        verbose=False, logger=None,\n",
    "    )\n",
    "\n",
    "def create_video(images, audios, outpath):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        process_one = functools.partial(process_one_clip, tmpdir)\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as tpe:\n",
    "            for i, _ in enumerate(tpe.map(process_one, range(len(images)), images, audios)):\n",
    "                logger.info(f'Done with {i} / {len(images)}')\n",
    "        # Concatenate all video clips\n",
    "        concatenate_videos(tmpdir, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5258b3b3-2cf4-4b72-962e-f27534d3c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpath = '/Users/jong/Downloads/Cell_20230725/final_video.mp4'\n",
    "# create_video([PIL.Image.open(io.BytesIO(base64.b64decode(img[1][\"b64_json\"]))) for img in images], audios, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d20726c-3fd1-4539-a782-3f954d007140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    def __init__(self, paper_path, outpath, skip_prereqs=False):\n",
    "        self.paper_path = paper_path\n",
    "        self.outpath = outpath\n",
    "        self.skip_prereqs = skip_prereqs\n",
    "\n",
    "    def run(self, script=None):\n",
    "        if script is None:\n",
    "            self.paper_text = extract_text_from_pdf(self.paper_path)\n",
    "            self.paper_sections = text_into_token_chunks(self.paper_text, smoothing=3)\n",
    "            if self.skip_prereqs:\n",
    "                self.paper_prereqs = None\n",
    "            else:\n",
    "                self.paper_prereqs = get_all_concepts(self.paper_sections)\n",
    "            self.paper_script = get_entire_script(self.paper_prereqs, self.paper_sections)\n",
    "        else:\n",
    "            self.paper_script = script\n",
    "    \n",
    "        def process_one_part(script):\n",
    "            images = get_images_from_text(script)\n",
    "            audios = script2speech([x[0] for x in images], SPEAKER_NAMES, SPEAKER_VOICES)\n",
    "            return images, audios\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as tpe:\n",
    "            runs = [tpe.submit(process_one_part, script) for script in self.paper_script if script]\n",
    "            images, audios = [None] * len(runs), [None] * len(runs)\n",
    "            for i, r in enumerate(concurrent.futures.as_completed(runs)):\n",
    "                ridx = runs.index(r)\n",
    "                imgs, auds = r.result()\n",
    "                images[ridx], audios[ridx] = imgs, auds\n",
    "                logger.info(f'Got images and audio for {i} / {len(runs)}')\n",
    "    \n",
    "        self.images = flatten_list(images)\n",
    "        self.audios = flatten_list(audios)\n",
    "        create_video([PIL.Image.open(io.BytesIO(base64.b64decode(img))) for _txt, img, _prompt in self.images], self.audios, self.outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dbe0973-4207-42fd-9e35-a9b348e983b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-11-10T21:08:42.060322Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:02.350873Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.364563Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-250_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.366536Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-247_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.367279Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-251_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.368490Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-248_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.370460Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-252_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.372986Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-245_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.378601Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-249_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:02.402856Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-246_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:03.508063Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-249_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.510515Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-252_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.515591Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-250_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.518028Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A chalkboard or screen with a mathematical formula for multiple linear regression, including several predictor variables.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-249_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.518851Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-247_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.520136Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A person looking perplexed or scratching their head in front of a complex diagram or equation.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-252_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.522787Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A man appears frustrated and confused, holding a piece of paper and standing in front of a government building with a \"MLR Application\" sign.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-250_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.528267Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An individual gazing thoughtfully at a crossroads signpost, symbolizing life choices, with a coin poised in the air between their fingers.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-247_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:03.652930Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-246_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:03.654130Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A person sitting at a restaurant table, looking puzzled while glancing at a menu with both soup and a sandwich visible.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-246_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:05.547006Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-251_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:05.548826Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A group of people laughing and interacting with various charts and graphs that illustrate different outcomes based on different factors.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-251_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:05.597695Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-248_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:05.598690Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image Two men engaged in an intense discussion, one looking perplexed or inquisitive while the other appears to be explaining a complicated matter.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-248_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:05.668142Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-245_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:05.669834Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image Two friends sitting across from each other in a casual setting, one of them looking curious and contemplative as he poses a question to the other.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-245_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:17.049015Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-246_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:17.789845Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-252_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:18.340977Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-255_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:18.343001Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 0 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:18.464396Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-249_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:18.579705Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-257_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:18.581028Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 1 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:19.302069Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-257_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:19.303826Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A stressed individual sitting at a desk with a test paper, with another person looking on sympathetically.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-257_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:19.890775Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-250_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:19.946397Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-251_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:20.005259Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-260_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:20.006989Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 2 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:20.015233Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-255_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:20.016046Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of a thoughtful individual analyzing a chart or graph with a magnifying glass, possibly with question marks or light bulbs above their head to symbolize the process of scrutiny and discovery.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-255_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:20.235361Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-247_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:21.347796Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-262_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:21.349705Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 3 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:21.857900Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-263_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:21.858934Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 4 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:22.499026Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-262_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:22.500562Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A pensive person leaning forward, listening intently with a hand on their chin.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-262_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:22.862752Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-260_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:22.866024Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of two people on a date, with one person smiling and animatedly talking while the other listens attentively, possibly with thought bubbles indicating attraction to personality traits.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-260_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:22.867092Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-263_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:22.881206Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-264_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:22.884207Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 5 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:23.783894Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-264_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:26.294364Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-248_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:27.257751Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-245_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:27.754398Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-267_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:27.756300Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 6 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:28.910906Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 7 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:28.911839Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-268_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:29.082646Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-267_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:30.011885Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-268_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:33.706398Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-255_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:33.925853Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-257_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:35.115324Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-271_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:35.116019Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 8 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:35.814803Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-272_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:35.816724Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 9 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:36.070759Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-271_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:36.397005Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-262_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:36.720603Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-260_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:37.226792Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-275_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:37.228836Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 10 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:37.487435Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-272_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:38.731697Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-276_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:09:38.732639Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 11 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:39.450275Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-275_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:09:39.790727Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-276_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:00.023632Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of an anxious individual standing at the edge of a sidewalk, visibly wary of an approaching bus labeled \"Relationship Pitfalls.\"\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-268_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:06.106671Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of someone thoughtfully examining a statistical chart or graph with a superimposed illustration of a mathematical formula representing the General Linear F-Test.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-271_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:07.490349Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An anxious man looking confused and slightly distressed while talking to his friend in a casual living room setting.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-272_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:07.880981Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A group of people standing around one person with a car key, looking thoughtful and ready to conduct an experiment.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-263_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:08.797589Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of a person proudly showing a bus ticket or pointing to a bus in the distance.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-264_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:09.462419Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An animated image of two men standing in front of a large, whimsical computer screen filled with complex charts and graphs, with one man enthusiastically pointing at the screen and the other man looking on with a mixture of curiosity and confusion, in a setting that suggests a magical forest made of swirling numbers and data points.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-275_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:09.802907Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An individual stands perplexedly between two checkout lanes, one offering paper bags and the other plastic bags, symbolizing a trivial yet seemingly difficult choice.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-276_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:14.093285Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A split-screen image of a person on one side with icons of a heart, car, and charm symbol above their head, and on the other side, a graph labeled \"Relationship Model\" with lines connecting different factors to a heart at the center.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-267_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:15.765050Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-268_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:17.182946Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-278_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:17.184878Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 12 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:18.272414Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-278_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:18.273904Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A chalkboard or whiteboard with mathematical equations and diagrams illustrating the concept of Sequential Sums of Squares.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-278_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:21.747253Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-271_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:22.182068Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-264_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:22.912264Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 13 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:22.912868Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-281_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:22.934302Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-263_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:23.261632Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-275_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:23.307630Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-272_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:23.873526Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-281_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:23.875040Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A man awkwardly dancing at a wedding, looking slightly embarrassed as others around him dance with more elegance.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-281_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:24.002631Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-285_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:24.003214Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 14 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:24.500470Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-286_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:24.501293Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 15 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:24.644929Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-276_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:24.992655Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-288_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:24.994967Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 16 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:25.372072Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-286_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:25.373881Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An animated couple with a man looking shocked while the woman excitedly holds opera glasses and a program.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-286_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:25.680591Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-285_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:25.682279Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An animated sequence of two cartoon characters resembling Jerry and George discussing near a blackboard covered in mathematical formulas, while one character demonstrates steps of a dance, symbolizing the incorporation of new information into a conceptual model.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-285_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:25.983035Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-289_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:25.984707Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 17 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:25.999027Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-288_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:26.442787Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-290_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:26.443855Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 18 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:27.112561Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-289_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:28.156402Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-290_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:28.173774Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-267_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:30.461148Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-292_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:30.461796Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 19 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:32.454916Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-292_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:32.542025Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-278_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:35.371251Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-294_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:35.372605Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 20 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:36.886628Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-294_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:37.343969Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-281_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:38.563909Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-296_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:38.564699Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 21 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:39.655419Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-296_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:41.537421Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-285_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:43.873319Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-298_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:43.875214Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 22 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:44.733599Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-298_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:47.518392Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-286_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:10:49.156942Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrequesting openai...          \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-300_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:10:49.157546Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 23 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:01.730208Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai...            \u001b[0m [\u001b[34m\u001b[1mChatPodcastGPT\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-300_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:01.732212Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image Two men raising glasses in a toast, one dressed in casual modern attire and the other in a pirate costume, with a book or screen displaying \"MLR - Multiple Linear Regression\" in the background.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-300_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:02.461086Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of a person standing on an upward-pointing arrow, symbolizing personal progress and moving forward in life.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-292_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:06.891961Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image An image of two friends in a lab filled with charts and graphs resembling multiple linear regression (MLR) models, pondering over a stack of papers and a computer with statistical software open.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-294_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:09.663433Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A man holding a \"puffy\" Renaissance-style shirt with a puzzled expression.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-296_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:11.007891Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A group of people in a meeting, with one person pointing out details on a data chart while others attentively listen and take notes.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-288_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:12.129454Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A frustrated individual sitting at a desk, looking puzzled, with charts and graphs depicting regression analysis spread out in front of them.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-289_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:13.169776Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image A man with a bemused expression is standing next to a friend, both surrounded by a variety of scattered objects representing errors or failures in different areas of life, such as a broken clock, a wilted plant, and an upset stomach illustration.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-290_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:14.738925Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1masking openai.image Two individuals standing in a laboratory setting, one looking thoughtful and the other embarrassed, wearing an excessively puffy shirt.\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-298_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:16.246799Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145733464064\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-292_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:16.359734Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145800622080\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-300_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:17.768477Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 24 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:18.011249Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 25 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:21.392181Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145767043072\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-294_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:22.876837Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 26 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:24.236682Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145699885056\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-296_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:25.236516Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145716674560\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-288_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:25.613506Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 27 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:26.822492Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145783832576\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-290_0\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:27.215572Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 28 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:28.329103Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 29 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:30.169870Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145750253568\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-298_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:31.379695Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mreceived openai.Image...      \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m123145683095552\u001b[0m \u001b[36mthread_name\u001b[0m=\u001b[35mThreadPoolExecutor-289_0\u001b[0m\n",
      "HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "\u001b[2m2023-11-10T21:11:32.341455Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 30 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:33.407764Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGot images and audio for 31 / 32\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:40.957640Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 0 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:44.210425Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 1 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:50.095022Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 2 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:50.099563Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 3 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:50.100950Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 4 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:50.102747Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 5 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:50.104370Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 6 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:50.105867Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 7 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:55.713153Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 8 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:55.715582Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 9 / 32              \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:57.680098Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 10 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:11:57.683077Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 11 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:01.896721Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 12 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:01.899229Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 13 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:10.433919Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 14 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:10.436334Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 15 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:10.438602Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 16 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:10.506338Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 17 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:17.887831Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 18 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:17.898508Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 19 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:17.900404Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 20 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:17.902045Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 21 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:27.404369Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 22 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:27.409321Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 23 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:28.632814Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 24 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:28.634018Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 25 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:28.635176Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 26 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:28.637655Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 27 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:28.638966Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 28 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:28.644883Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 29 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:31.055033Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 30 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "\u001b[2m2023-11-10T21:12:32.273648Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone with 31 / 32             \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \u001b[36mthread_id\u001b[0m=\u001b[35m[Main]\u001b[0m\n",
      "ffmpeg -f concat -safe 0 -i /var/folders/kx/xrqgq16n2yn81hvm8wgy8d440000gr/T/tmpk9zo_jdk/_files.txt -c copy /Users/jong/Downloads/stats06_20231109.mp4\n",
      "CPU times: user 16.4 s, sys: 20 s, total: 36.4 s\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SPEAKER_NAMES = ['Jerry', 'George'][::-1]\n",
    "adjectives = 'intuitive, educational, and funny'\n",
    "style = ' in the style of a hilarious conversation between Jerry Seinfeld and George Costanza'\n",
    "title = \"\"\"Title: Navigating MLR Model Evaluation - Mastering Hypothesis Tests in Multiple Regression!\n",
    "Outline:\n",
    "Introduction\n",
    "Kickoff Remarks\n",
    "Introduction to the importance of model evaluation in Multiple Linear Regression (MLR).\n",
    "Overview of the different types of hypothesis tests in MLR.\n",
    "Section 1: Hypothesis Testing in MLR\n",
    "Basics of Hypothesis Testing\n",
    "Refreshing the concept of hypothesis testing in statistical analysis.\n",
    "Transition from Simple Linear Regression to MLR in the context of hypothesis testing.\n",
    "Three Types of Hypothesis Tests in MLR\n",
    "Test for a single slope parameter being 0.\n",
    "Test for all slope parameters being 0.\n",
    "Test for a subset of slope parameters being 0.\n",
    "Section 2: The General Linear F-Test\n",
    "Understanding the General Linear F-Test\n",
    "Introduction and explanation of the General Linear F-test.\n",
    "Its role and significance in performing hypothesis tests in MLR.\n",
    "Applying the F-Test in MLR\n",
    "Step-by-step guide on conducting the General Linear F-test.\n",
    "Interpreting the results of the F-test in the context of MLR.\n",
    "Section 3: Sequential Sums of Squares\n",
    "Exploring Sequential Sums of Squares\n",
    "What are Sequential Sums of Squares and their relevance in MLR?\n",
    "How Sequential Sums of Squares tie into hypothesis testing.\n",
    "Computational Approach\n",
    "Demonstration of calculating Sequential Sums of Squares.\n",
    "Practical examples and case studies.\n",
    "Section 4: Performing Hypothesis Tests in MLR\n",
    "Detailed Walkthrough\n",
    "Step-by-step instructions on performing each of the three types of hypothesis tests in MLR.\n",
    "Using software tools and coding examples for conducting these tests.\n",
    "Interpretation of Test Results\n",
    "How to interpret the outcomes of these hypothesis tests.\n",
    "Understanding the implications of these tests for MLR model evaluation.\n",
    "Section 5: Practical Application and Common Missteps\n",
    "Real-World Applications\n",
    "Applying these tests in different data scenarios.\n",
    "Case studies showcasing the use of hypothesis testing in MLR.\n",
    "Avoiding Pitfalls\n",
    "Common errors to avoid in MLR hypothesis testing.\n",
    "Best practices for robust and accurate model evaluation.\n",
    "Conclusion\n",
    "Summing Up the Lesson\n",
    "Recap of the key points and their practical importance.\n",
    "Preview of what's next in the course.\n",
    "\"\"\"\n",
    "chat = Chat(f'''Turn a video's info into a long script{style}.\n",
    "Make it {adjectives}.\n",
    "There are two speakers, {' and '.join(SPEAKER_NAMES)}.\n",
    "Prefix each speaker's lines with their name and a :, like the following.\n",
    "{SPEAKER_NAMES[0]}: \n",
    "{SPEAKER_NAMES[1]}: \n",
    "Do not include any other script syntax.'''.replace('\\n', ' '), max_length=MAX_TOKENS)\n",
    "text = chat.message(\n",
    "    title,\n",
    "    model=MODEL,\n",
    ")\n",
    "outpath = '/Users/jong/Downloads/stats06_20231109.mp4'\n",
    "MAX_WORKERS = 8\n",
    "runner = Runner(None, outpath, skip_prereqs=True)\n",
    "runner.run(script=[x for x in text.split('\\n') if x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2058fa-75be-4b73-ab77-7d75d929fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([t.split(': ', maxsplit=1)[1] for t, *_ in runner.images]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dffaf5d7-f5ec-4c99-91ac-8224f09fceb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # paper_path = '/Users/jong/Downloads/covid_garbage.pdf'\n",
    "# paper_path  = '/Users/jong/Downloads/2311.02745.pdf'\n",
    "# outpath = (paper_path[:-4] + '.mp4').replace(' ', '_')\n",
    "# MAX_WORKERS = 8\n",
    "# runner = Runner(paper_path, outpath, skip_prereqs=True)\n",
    "# runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b64fd3af-13d5-4065-b1e7-b10e9ce0debd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for txt, img, prompt in runner.images:\n",
    "#     img = PIL.Image.open(io.BytesIO(base64.b64decode(img)))\n",
    "#     IPython.display.display(txt)\n",
    "#     IPython.display.display(prompt)\n",
    "#     IPython.display.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c840a28c-288c-4921-a445-4f83c64d511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_video([PIL.Image.open(io.BytesIO(base64.b64decode(img))) for _txt, img, _prompt in runner.images], runner.audios, runner.outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ec6ac-96e0-4ccf-8117-8e245c45d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613af4e1-15f8-45ad-bf87-c285f25be7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
